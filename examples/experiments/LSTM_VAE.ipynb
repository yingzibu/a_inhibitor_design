{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNuOlIE97tz+/t3AubdNAJU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yingzibu/a_inhibitor_design/blob/main/examples/experiments/LSTM_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guMw4q3_Ny2m"
      },
      "outputs": [],
      "source": [
        "https://github.com/bayeslabs/genmol/blob/master/genmol/vae/data.py\n",
        "\n",
        "https://github.com/aspuru-guzik-group/selfies/blob/master/examples/vae_example/chemistry_vae.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBv9jzHUOZvs",
        "outputId": "f45d5782-0fbc-4125-faac-c1d61aba3601"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install PyTDC --quiet\n",
        "! pip install selfies"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TATwSsrOuvk",
        "outputId": "c49da671-a930-4a18-9063-b24601b8d574"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/107.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/107.7 kB\u001b[0m \u001b[31m875.9 kB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m102.4/107.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for PyTDC (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tdc.generation import MolGen\n",
        "import selfies as sf\n",
        "from tqdm import tqdm\n",
        "data = MolGen(name = 'ZINC')\n",
        "split = data.get_split()\n",
        "train = split['train']\n",
        "valid = split['valid']\n",
        "test = split['test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7iGrSZoOwtJ",
        "outputId": "c16a2b61-725d-4a60-f882-0bfef27a6682"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "100%|██████████| 11.8M/11.8M [00:00<00:00, 24.6MiB/s]\n",
            "Loading...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD_v3EJYQCM1",
        "outputId": "280ccb00-2a28-4e46-d311-c3f8d875eb80"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_smiles = []\n",
        "for benzene in tqdm(train['smiles']):\n",
        "    try:\n",
        "        benzene_sf = sf.encoder(benzene)  # [C][=C][C][=C][C][=C][Ring1][=Branch1]\n",
        "        benzene_smi = sf.decoder(benzene_sf)  # C1=CC=CC=C1\n",
        "        length = sf.len_selfies(benzene_sf)  # 8\n",
        "        if length < 20:\n",
        "            small_smiles.append(benzene)\n",
        "    except sf.EncoderError:\n",
        "        pass  # sf.encoder error!\n",
        "    except sf.DecoderError:\n",
        "        pass  # sf.decoder error!\n",
        "\n",
        "\n",
        "    # symbols_benzene = list(sf.split_selfies(benzene_sf))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUsiSCaLPA2R",
        "outputId": "fa58a8be-5965-4e73-cbb2-8c6e2239cfb6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 174618/174618 [03:23<00:00, 858.89it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# del len\n",
        "alphabet= sf.get_alphabet_from_selfies(small_smiles)\n",
        "alphabet.add(\"[nop]\", '[bos]', '[eos]', '[unk]')\n",
        "len(alphabet)"
      ],
      "metadata": {
        "id": "egpbT40mPD4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "chars = set()\n",
        "for string in small_smiles:\n",
        "    chars.update(string)\n",
        "all_sys = sorted(list(chars)) + ['<bos>', '<eos>', '<pad>', '<unk>']\n",
        "vocab = all_sys\n",
        "c2i = {c: i for i, c in enumerate(all_sys)}\n",
        "i2c = {i: c for i, c in enumerate(all_sys)}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vector = torch.eye(len(c2i))\n",
        "\n",
        "def char2id(char):\n",
        "    if char not in c2i:\n",
        "        return c2i['<unk>']\n",
        "    else:\n",
        "        return c2i[char]\n",
        "\n",
        "\n",
        "def id2char(id):\n",
        "    if id not in i2c:\n",
        "        return i2c[32]\n",
        "    else:\n",
        "        return i2c[id]\n",
        "\n",
        "def string2ids(string,add_bos=False, add_eos=False):\n",
        "    ids = [char2id(c) for c in string]\n",
        "    if add_bos:\n",
        "        ids = [c2i['<bos>']] + ids\n",
        "    if add_eos:\n",
        "        ids = ids + [c2i['<eos>']]\n",
        "    return ids\n",
        "def ids2string(ids, rem_bos=True, rem_eos=True):\n",
        "    if len(ids) == 0:\n",
        "        return ''\n",
        "    if rem_bos and ids[0] == c2i['<bos>']:\n",
        "        ids = ids[1:]\n",
        "    if rem_eos and ids[-1] == c2i['<eos>']:\n",
        "        ids = ids[:-1]\n",
        "    string = ''.join([id2char(id) for id in ids])\n",
        "    return string\n",
        "def string2tensor(string, device='model'):\n",
        "    ids = string2ids(string, add_bos=True, add_eos=True)\n",
        "    tensor = torch.tensor(ids, dtype=torch.long,device=device if device == 'model' else device)\n",
        "    return tensor\n",
        "tensor = [string2tensor(string, device=device) for string in small_smiles]\n",
        "vector = torch.eye(len(c2i))  # (alphabet_len, alphabet_len)"
      ],
      "metadata": {
        "id": "zkL7tGb5Pc2b"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "q_bidir = True\n",
        "q_d_h = 256\n",
        "q_n_layers = 1\n",
        "q_dropout = 0.5\n",
        "d_n_layers = 3\n",
        "d_dropout = 0\n",
        "d_z = 128\n",
        "d_d_h = 512\n",
        "# from data import *\n",
        "class VAE(nn.Module):\n",
        "  def __init__(self,vocab,vector):\n",
        "    super().__init__()\n",
        "    self.vocabulary = vocab\n",
        "    self.vector = vector\n",
        "\n",
        "    n_vocab, d_emb = len(vocab), vector.size(1)\n",
        "    self.x_emb = nn.Embedding(n_vocab, d_emb, c2i['<pad>'])\n",
        "    self.x_emb.weight.data.copy_(vector)\n",
        "\n",
        "    #ENCODER\n",
        "\n",
        "    self.encoder_rnn = nn.GRU(d_emb,q_d_h,num_layers=q_n_layers,batch_first=True,dropout=q_dropout if q_n_layers > 1 else 0,bidirectional=q_bidir)\n",
        "    q_d_last = q_d_h * (2 if q_bidir else 1)\n",
        "    self.q_mu = nn.Linear(q_d_last, d_z)\n",
        "    self.q_logvar = nn.Linear(q_d_last, d_z)\n",
        "\n",
        "\n",
        "\n",
        "    # Decoder\n",
        "    self.decoder_rnn = nn.GRU(d_emb + d_z,d_d_h,num_layers=d_n_layers,batch_first=True,dropout=d_dropout if d_n_layers > 1 else 0)\n",
        "    self.decoder_latent = nn.Linear(d_z, d_d_h)\n",
        "    self.decoder_fullyc = nn.Linear(d_d_h, n_vocab)\n",
        "\n",
        "\n",
        "\n",
        "    # Grouping the model's parameters\n",
        "    self.encoder = nn.ModuleList([self.encoder_rnn,self.q_mu,self.q_logvar])\n",
        "    self.decoder = nn.ModuleList([self.decoder_rnn,self.decoder_latent,self.decoder_fullyc])\n",
        "    self.vae = nn.ModuleList([self.x_emb,self.encoder,self.decoder])\n",
        "\n",
        "\n",
        "\n",
        "  @property\n",
        "  def device(self):\n",
        "    return next(self.parameters()).device\n",
        "\n",
        "  def string2tensor(self, string, device='model'):\n",
        "    ids = string2ids(string, add_bos=True, add_eos=True)\n",
        "    tensor = torch.tensor(ids, dtype=torch.long,device=self.device if device == 'model' else device)\n",
        "    return tensor\n",
        "\n",
        "  def tensor2string(self, tensor):\n",
        "    ids = tensor.tolist()\n",
        "    string = ids2string(ids, rem_bos=True, rem_eos=True)\n",
        "    return string\n",
        "\n",
        "  def forward(self,x):\n",
        "    z, kl_loss = self.forward_encoder(x)\n",
        "    recon_loss = self.forward_decoder(x, z)\n",
        "    # print(\"forward\")\n",
        "    return kl_loss, recon_loss\n",
        "\n",
        "  def forward_encoder(self,x):\n",
        "    x = [self.x_emb(i_x) for i_x in x]\n",
        "    x = nn.utils.rnn.pack_sequence(x)\n",
        "    _, h = self.encoder_rnn(x, None)\n",
        "    h = h[-(1 + int(self.encoder_rnn.bidirectional)):]\n",
        "    h = torch.cat(h.split(1), dim=-1).squeeze(0)\n",
        "    mu, logvar = self.q_mu(h), self.q_logvar(h)\n",
        "    eps = torch.randn_like(mu)\n",
        "    z = mu + (logvar / 2).exp() * eps\n",
        "    kl_loss = 0.5 * (logvar.exp() + mu ** 2 - 1 - logvar).sum(1).mean()\n",
        "    return z, kl_loss\n",
        "\n",
        "  def forward_decoder(self,x, z):\n",
        "    lengths = [len(i_x) for i_x in x]\n",
        "    x = nn.utils.rnn.pad_sequence(x, batch_first=True, padding_value= c2i['<pad>'])\n",
        "    x_emb = self.x_emb(x)\n",
        "    z_0 = z.unsqueeze(1).repeat(1, x_emb.size(1), 1)\n",
        "    x_input = torch.cat([x_emb, z_0], dim=-1)\n",
        "    x_input = nn.utils.rnn.pack_padded_sequence(x_input, lengths, batch_first=True)\n",
        "    h_0 = self.decoder_latent(z)\n",
        "    h_0 = h_0.unsqueeze(0).repeat(self.decoder_rnn.num_layers, 1, 1)\n",
        "    output, _ = self.decoder_rnn(x_input, h_0)\n",
        "    output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
        "    y = self.decoder_fullyc(output)\n",
        "\n",
        "    recon_loss = F.cross_entropy(y[:, :-1].contiguous().view(-1, y.size(-1)),x[:, 1:].contiguous().view(-1),ignore_index= c2i['<pad>'])\n",
        "    return recon_loss\n",
        "\n",
        "\n",
        "  def sample_z_prior(self,n_batch):\n",
        "    return torch.randn(n_batch,self.q_mu.out_features,device= self.x_emb.weight.device)\n",
        "\n",
        "  def sample(self,n_batch, max_len=100, z=None, temp=1.0):\n",
        "    with torch.no_grad():\n",
        "      if z is None:\n",
        "        z = self.sample_z_prior(n_batch)\n",
        "        z = z.to(self.device)\n",
        "        z_0 = z.unsqueeze(1)\n",
        "        h = self.decoder_latent(z)\n",
        "        h = h.unsqueeze(0).repeat(self.decoder_rnn.num_layers, 1, 1)\n",
        "        w = torch.tensor(c2i['<bos>'], device=self.device).repeat(n_batch)\n",
        "        x = torch.tensor([c2i['<pad>']], device=device).repeat(n_batch, max_len)\n",
        "        x[:, 0] = c2i['<bos>']\n",
        "        end_pads = torch.tensor([max_len], device=self.device).repeat(n_batch)\n",
        "        eos_mask = torch.zeros(n_batch, dtype=torch.uint8, device=self.device)\n",
        "\n",
        "\n",
        "        for i in range(1, max_len):\n",
        "          x_emb = self.x_emb(w).unsqueeze(1)\n",
        "          x_input = torch.cat([x_emb, z_0], dim=-1)\n",
        "\n",
        "          o, h = self.decoder_rnn(x_input, h)\n",
        "          y = self.decoder_fullyc(o.squeeze(1))\n",
        "          y = F.softmax(y / temp, dim=-1)\n",
        "\n",
        "          w = torch.multinomial(y, 1)[:, 0]\n",
        "          x[~eos_mask, i] = w[~eos_mask]\n",
        "          i_eos_mask = ~eos_mask & (w == c2i['<eos>'])\n",
        "          end_pads[i_eos_mask] = i + 1\n",
        "          eos_mask = eos_mask | i_eos_mask\n",
        "\n",
        "\n",
        "          new_x = []\n",
        "          for i in range(x.size(0)):\n",
        "            new_x.append(x[i, :end_pads[i]])\n",
        "\n",
        "\n",
        "    return [self.tensor2string(i_x) for i_x in new_x]"
      ],
      "metadata": {
        "id": "1Nu-yp11Rxz8"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "import math\n",
        "import numpy as np\n",
        "from collections import UserList, defaultdict\n",
        "n_last = 1000\n",
        "n_batch = 32\n",
        "kl_start = 0\n",
        "kl_w_start = 0.0\n",
        "kl_w_end = 1.0\n",
        "n_epoch = 50\n",
        "n_workers = 0\n",
        "\n",
        "clip_grad  = 50\n",
        "lr_start = 0.003\n",
        "lr_n_period = 10\n",
        "lr_n_mult = 1\n",
        "lr_end = 3 * 1e-4\n",
        "lr_n_restarts = 6\n",
        "\n",
        "# from data import *\n",
        "\n",
        "def _n_epoch():\n",
        "    return sum(lr_n_period * (lr_n_mult ** i) for i in range(lr_n_restarts))\n",
        "\n",
        "def _train_epoch(model, epoch, train_loader, kl_weight, optimizer=None):\n",
        "    if optimizer is None:\n",
        "        model.eval()\n",
        "    else:\n",
        "        model.train()\n",
        "\n",
        "    kl_loss_values = CircularBuffer(n_last)\n",
        "    recon_loss_values = CircularBuffer(n_last)\n",
        "    loss_values = CircularBuffer(n_last)\n",
        "    for i, input_batch in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
        "        input_batch = tuple(data.to(device) for data in input_batch)\n",
        "\n",
        "    #forward\n",
        "        kl_loss, recon_loss = model(input_batch)\n",
        "        loss = kl_weight * kl_loss + recon_loss\n",
        "    #backward\n",
        "        if optimizer is not None:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            clip_grad_norm_(get_optim_params(model), clip_grad)\n",
        "            optimizer.step()\n",
        "\n",
        "        kl_loss_values.add(kl_loss.item())\n",
        "        recon_loss_values.add(recon_loss.item())\n",
        "        loss_values.add(loss.item())\n",
        "        lr = (optimizer.param_groups[0]['lr'] if optimizer is not None else None)\n",
        "\n",
        "    #update train_loader\n",
        "        kl_loss_value = kl_loss_values.mean()\n",
        "        recon_loss_value = recon_loss_values.mean()\n",
        "        loss_value = loss_values.mean()\n",
        "        postfix = [f'loss={loss_value:.5f}',f'(kl={kl_loss_value:.5f}',f'recon={recon_loss_value:.5f})',f'klw={kl_weight:.5f} lr={lr:.5f}']\n",
        "    postfix = {'epoch': epoch,'kl_weight': kl_weight,'lr': lr,'kl_loss': kl_loss_value,'recon_loss': recon_loss_value,'loss': loss_value,'mode': 'Eval' if optimizer is None else 'Train'}\n",
        "    print(postfix)\n",
        "    return postfix\n",
        "\n",
        "def _train(model, train_loader, val_loader=None, logger=None):\n",
        "    optimizer = optim.Adam(get_optim_params(model),lr= lr_start)\n",
        "\n",
        "    lr_annealer = CosineAnnealingLRWithRestart(optimizer)\n",
        "\n",
        "    model.zero_grad()\n",
        "    for epoch in range(n_epoch):\n",
        "\n",
        "        kl_annealer = KLAnnealer(n_epoch)\n",
        "        kl_weight = kl_annealer(epoch)\n",
        "        postfix = _train_epoch(model, epoch, train_loader, kl_weight, optimizer)\n",
        "        lr_annealer.step()\n",
        "\n",
        "def fit(model, train_data, val_data=None):\n",
        "    logger = Logger() if False is not None else None\n",
        "    train_loader = get_dataloader(model, train_data, shuffle=True)\n",
        "\n",
        "\n",
        "    val_loader = None if val_data is None else get_dataloader(model, val_data, shuffle=False)\n",
        "    _train(model, train_loader, val_loader, logger)\n",
        "    return model\n",
        "\n",
        "def get_collate_device(model):\n",
        "    return model.device\n",
        "def get_dataloader(model, train_data, collate_fn=None, shuffle=True):\n",
        "    if collate_fn is None:\n",
        "        collate_fn = get_collate_fn(model)\n",
        "        print(collate_fn)\n",
        "    return DataLoader(train_data, batch_size=n_batch, shuffle=shuffle, num_workers=n_workers, collate_fn=collate_fn)\n",
        "\n",
        "def get_collate_fn(model):\n",
        "    device = get_collate_device(model)\n",
        "\n",
        "    def collate(train_data):\n",
        "        train_data.sort(key=len, reverse=True)\n",
        "        tensors = [string2tensor(string, device=device) for string in train_data]\n",
        "        return tensors\n",
        "\n",
        "    return collate\n",
        "\n",
        "def get_optim_params(model):\n",
        "    return (p for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "class KLAnnealer:\n",
        "    def __init__(self,n_epoch):\n",
        "        self.i_start = kl_start\n",
        "        self.w_start = kl_w_start\n",
        "        self.w_max = kl_w_end\n",
        "        self.n_epoch = n_epoch\n",
        "\n",
        "\n",
        "        self.inc = (self.w_max - self.w_start) / (self.n_epoch - self.i_start)\n",
        "\n",
        "    def __call__(self, i):\n",
        "        k = (i - self.i_start) if i >= self.i_start else 0\n",
        "        return self.w_start + k * self.inc\n",
        "\n",
        "\n",
        "\n",
        "class CosineAnnealingLRWithRestart(_LRScheduler):\n",
        "    def __init__(self , optimizer):\n",
        "        self.n_period = lr_n_period\n",
        "        self.n_mult = lr_n_mult\n",
        "        self.lr_end = lr_end\n",
        "\n",
        "        self.current_epoch = 0\n",
        "        self.t_end = self.n_period\n",
        "\n",
        "        # Also calls first epoch\n",
        "        super().__init__(optimizer, -1)\n",
        "\n",
        "    def get_lr(self):\n",
        "        return [self.lr_end + (base_lr - self.lr_end) *\n",
        "                (1 + math.cos(math.pi * self.current_epoch / self.t_end)) / 2\n",
        "                for base_lr in self.base_lrs]\n",
        "\n",
        "    def step(self, epoch=None):\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch + 1\n",
        "        self.last_epoch = epoch\n",
        "        self.current_epoch += 1\n",
        "\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        if self.current_epoch == self.t_end:\n",
        "            self.current_epoch = 0\n",
        "            self.t_end = self.n_mult * self.t_end\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CircularBuffer:\n",
        "    def __init__(self, size):\n",
        "        self.max_size = size\n",
        "        self.data = np.zeros(self.max_size)\n",
        "        self.size = 0\n",
        "        self.pointer = -1\n",
        "\n",
        "    def add(self, element):\n",
        "        self.size = min(self.size + 1, self.max_size)\n",
        "        self.pointer = (self.pointer + 1) % self.max_size\n",
        "        self.data[self.pointer] = element\n",
        "        return element\n",
        "\n",
        "    def last(self):\n",
        "        assert self.pointer != -1, \"Can't get an element from an empty buffer!\"\n",
        "        return self.data[self.pointer]\n",
        "\n",
        "    def mean(self):\n",
        "        return self.data.mean()\n",
        "\n",
        "\n",
        "class Logger(UserList):\n",
        "    def __init__(self, data=None):\n",
        "        super().__init__()\n",
        "        self.sdata = defaultdict(list)\n",
        "        for step in (data or []):\n",
        "            self.append(step)\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        if isinstance(key, int):\n",
        "            return self.data[key]\n",
        "        elif isinstance(key, slice):\n",
        "            return Logger(self.data[key])\n",
        "        else:\n",
        "            ldata = self.sdata[key]\n",
        "            if isinstance(ldata[0], dict):\n",
        "                return Logger(ldata)\n",
        "            else:\n",
        "                return ldata\n",
        "\n",
        "    def append(self, step_dict):\n",
        "        super().append(step_dict)\n",
        "        for k, v in step_dict.items():\n",
        "            self.sdata[k].append(v)"
      ],
      "metadata": {
        "id": "oAsELqWzR0fL"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "n_samples = 3000\n",
        "n_jobs = 1\n",
        "max_len = 100\n",
        "\n",
        "class sample():\n",
        "  def take_samples(model,n_batch):\n",
        "    n = n_samples\n",
        "    samples = []\n",
        "    with tqdm(total=n_samples, desc='Generating samples') as T:\n",
        "      while n > 0:\n",
        "        current_samples = model.sample(min(n, n_batch), max_len)\n",
        "        samples.extend(current_samples)\n",
        "        n -= len(current_samples)\n",
        "        T.update(len(current_samples))\n",
        "    samples = pd.DataFrame(samples, columns=['SMILES'])\n",
        "    return samples"
      ],
      "metadata": {
        "id": "q-ME9XfBSlZY"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VAE(vocab,vector).to(device)\n",
        "fit(model, small_smiles)\n",
        "model.eval()\n",
        "sample = sample.take_samples(model, n_batch)\n",
        "print(sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGTqrK6dS5sM",
        "outputId": "dbe20eb9-c728-4bf3-f172-5c8be1c33b5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<function get_collate_fn.<locals>.collate at 0x7cea5a42beb0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [01:16<00:00,  1.10s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 0, 'kl_weight': 0.0, 'lr': 0.0029339262969984574, 'kl_loss': 2.29802419783175, 'recon_loss': 0.17999264967441558, 'loss': 0.17999264967441558, 'mode': 'Train'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 1, 'kl_weight': 0.02, 'lr': 0.0027421729424061793, 'kl_loss': 0.16628725191950797, 'recon_loss': 0.0971608543395996, 'loss': 0.10048659932613373, 'mode': 'Train'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [01:13<00:00,  1.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 2, 'kl_weight': 0.04, 'lr': 0.002443510090594839, 'kl_loss': 0.009557408839464187, 'recon_loss': 0.0745278457403183, 'loss': 0.07491014182567596, 'mode': 'Train'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [01:12<00:00,  1.04s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 3, 'kl_weight': 0.06, 'lr': 0.002067172942406179, 'kl_loss': 0.003410394726321101, 'recon_loss': 0.06721239495277405, 'loss': 0.0674170189499855, 'mode': 'Train'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [01:15<00:00,  1.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 4, 'kl_weight': 0.08, 'lr': 0.00165, 'kl_loss': 0.0012498058564960957, 'recon_loss': 0.0626366199851036, 'loss': 0.06273660457134247, 'mode': 'Train'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [01:13<00:00,  1.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 5, 'kl_weight': 0.1, 'lr': 0.0012328270575938211, 'kl_loss': 0.0005630117375403643, 'recon_loss': 0.058987684965133666, 'loss': 0.05904398626089096, 'mode': 'Train'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [01:15<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 6, 'kl_weight': 0.12, 'lr': 0.0008564899094051615, 'kl_loss': 0.0003633645889349282, 'recon_loss': 0.055854525327682494, 'loss': 0.05589812880754471, 'mode': 'Train'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 70/70 [01:15<00:00,  1.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 7, 'kl_weight': 0.14, 'lr': 0.0005578270575938211, 'kl_loss': 0.00027614202699624004, 'recon_loss': 0.053557440161705015, 'loss': 0.053596100032329556, 'mode': 'Train'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▊      | 27/70 [00:30<00:49,  1.16s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O7BO3X_lS547"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}